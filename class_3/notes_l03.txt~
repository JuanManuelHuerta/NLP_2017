

Juan M. Huerta
jmhuertany@gmail.com


Class 3: Vector representation, cosine similarity, document clustering
       we will use python's SimpleHTTPServer 


III.0.  Overview of first 2 classes. 
	Overview of class 3: switch scenario



III.1   TF-IDF  Term Frequency Inverse document frequency: per product  
       https://en.wikipedia.org/wiki/Tf%E2%80%93idf
       (a)      Introduce Scenario # 2
          Challenge Scenario # 2:  Identify the product space, Clustering
       (b) Switching to Product based analysis                                    [l03s01]

III.2. Document Similarity (Intro and Oeverview for next class)                    [l03s02]
      (a) Similarity of word distributions
      (b) Cosine similarity
      (c) Projections (the problem of synonimity)
      (d) Computing Complexity
      
      Similarity matrix
      Compute a similarity graph

III.3  Graph Commeunities and Visualization				
       d3 
       html  page
       http://bl.ocks.org/ccmcc/5182685
       curl  http://bl.ocks.org/ccmcc/raw/5182685/ > index.html
       python -m SimpleHTTPServer


III.4  Dealing with Synonims, LSTM's and other interesting topics
       Word2vec and gensim


III.5 Summary of the class







=================


NLTK:
http://www.nltk.org/

Entropy:
https://en.wikipedia.org/wiki/Entropy_(information_theory)
https://en.wikipedia.org/wiki/Mutual_information


Bayes Theorem:
https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/


Computational Complexity:
https://en.wikipedia.org/wiki/Computational_complexity_theory
https://en.wikipedia.org/wiki/Big_O_notation



TF-IDF
http://trimc-nlp.blogspot.com/2013/04/tfidf-with-google-n-grams-and-pos-tags.html


Nice paper:
Naive Bayes and text classificaiton
https://arxiv.org/pdf/1410.5329.pdf

KL Divergence
https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained

